\section{APIs, Interoperability, Reuse, and Standards}
\label{sec:interoperability}

There has been an explosion of workflow technologies in the last decade~\cite{workflow-systems}. Individual workflow systems often serve a particular user community, a specific underlying compute infrastructure, a dedicated software engineering vision, or follow a specific historical trait. As a result, there are substantial technical and conceptual overlaps. Reasons for divergence include (i)~use cases require different workflow structures, (ii)~organizations have very different optimization goals, (iii)~predefined execution systems provide fundamentally different capabilities, or (iv)~availability and scarcity of different types of resources. Another reason is that it is relatively easy to start building a workflow system for a specific narrow focus (i.e., these systems have a gentle software development curve~\cite{SDCblog}), leading to large numbers of packages that provide some basic functionality, and developers who are subject to the sunk cost fallacy and then continue to invest in their custom packages, rather than joining forces and building community packages. This divergence leads to missed opportunities for interoperability. It is often difficult for workflows to be ported across systems, for system components to be interchanged, for provenance to be captured and exploited in similar ways, and for developers to leverage different execution engines, schedulers, or monitoring services.


%% Subsection
\subsection{Brief State-of-the-art and Challenges}

Workflow systems often grow organically: developers start by solving a concrete problem and they end up with a new workflow system. In some cases, workflow systems may \textbf{\emph{differ by design}}, rather than by accident. For example, they offer fundamentally different abstractions or models for a workflow: DAG-structured \emph{vs.} recursive, imperative \emph{vs.} declarative, data flow \emph{vs.} control (and data) flow. These fundamental differences, catering for different use cases, make it such that full interoperability may simply not be possible. 
However, in spite of these differences, workflow systems are often implemented with many layers and components that may be interchangeable, for example, workflow specifications, task descriptions, data passing methods, file handling, and task execution engines. Interoperability at some layers is likely to be more impactful than others; for instance, being able to run the same workflow specification (with appropriately encapsulated task implementations) on different workflow infrastructures would be a major relief for users trying to reuse workflows implemented in other organizations. Further, interoperability does not need to imply agreement and for workflow systems to implement a standard interface; instead, it may occur via shim layers or intermediate representations, in a similar manner to compiling to a high level language. With the reuse goal, projects as eFlows4HPC proposes the HPC Workflows as a Service (HPCWaaS) methodology, where workflows will be defined by expert developers and provided as a service to community users~\cite{eflows}.

Most efforts to unify workflow systems and/or their components have led to the definition of various specifications developed by a subset of the community~\cite{terstyanszky2014enabling, cwl-annotations}. However, the specialization of some of these specifications may require that other systems conform to that specification, thus resulting in low adoption. Attempts to standardize also may lead to overly generic interfaces that in the end inhibit usability and lead to hidden incompatibilities. 

A particularly pressing problem at the interface of workflow technology and HPC systems is the need for a \textbf{\emph{common submission model}} that is compatible with heterogeneous platforms. The differences between the methods by which workflow engines, schedulers, and execution engines interact is a universal challenge faced by workflow developers when trying to target multiple infrastructures underlying long-lasting design decisions. Further challenges relate to authentication and authorization models deployed on many systems (e.g., two-factor authentication). Some efforts in this area are currently undergoing~\cite{JLESC-common-registry}.


%% Subsection
\subsection{A Vision for Potential Community Activities}

An immediate and continuous action would be to host several \textbf{\emph{``bake-offs''}} to compare workflow systems, including task and workflow definitions, a benchmark set of workflows with defined input and output data, as well as job execution interfaces. This would entail engaging participants to write and execute these workflows and identify commonalities between systems. A successful example is the GA4GH-DREAM challenge~\cite{ga4gh}. An open question is whether such attempts should be domain-specific or domain-overarching;  there is likely a greater opportunity for standardization within domains (and indeed some domains have already made significant progress), but domain-specific standards would only partly solve the interoperability problem. The workflow community should then review these areas, determine and then publicize what has worked, and build on successful prior efforts.

With the emergence of FaaS (Function-as-a-Service) platforms (e.g., AWS Lambda, Azure Durable Functions, Google Cloud Functions, IBM Composer), or CaaS (Container-as-a-Service) services (e.g. AWS Fargate, Google Cloud Run), the community should identify a set of \textbf{\emph{suggested use cases}} and compare them against an implementation with popular or recently developed FaaS-enabled workflow systems~\cite{chard2020funcx, smirnov2020apollo, malawski2020serverless}. Such a comparison may identify complementary features that can benefit both industry and the workflows community. In addition to features, a set of common workflow patterns could also be identified. However, there is still some uncertainty regarding the scope of previously developed patterns (e.g., for representing patterns in dynamic workflows). Thus, it is necessary to \textbf{\emph{survey published patterns}}~\cite{workflowpatterns,garijo2014common} and identify gaps seen by the community.

Although the above proposed activities have the potential to advance interoperability, the current funding and research recognition models often implicitly work against standardization by constantly requiring innovative ideas even in areas where outreach, uptake, and maintenance rather than innovation seems to be the most pressing problem. Developing \textbf{\emph{sustained funding models}} for building and evolving workflow standards, encouraging their adoption, supporting interoperability, testing, and providing user and developer training would help address these challenges. 
